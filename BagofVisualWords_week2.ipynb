{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Parts we added\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Added for week 2\n",
    "from numpy import linalg as LA\n",
    "from sklearn.preprocessing import power_transform\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_filenames = pickle.load(open('train_images_filenames.dat','rb'))\n",
    "test_images_filenames = pickle.load(open('test_images_filenames.dat','rb'))\n",
    "train_images_filenames = ['..' + n[15:] for n in train_images_filenames]\n",
    "test_images_filenames  = ['..' + n[15:] for n in test_images_filenames]\n",
    "train_labels = pickle.load(open('train_labels.dat','rb'))\n",
    "test_labels = pickle.load(open('test_labels.dat','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We created functions to get SIFT descriptors and calculate Dense SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dense_kp(img_shape, step_size):\n",
    "    return [cv2.KeyPoint(x, y, step_size) for y in range(0, img_shape[0], step_size) \n",
    "                                          for x in range(0, img_shape[1], step_size)]\n",
    "\n",
    "def get_descriptors(dense=True, feat_num=250, step_size=20, mode=\"train\"):\n",
    "    \n",
    "    descriptors = []\n",
    "    label_per_descriptor = []\n",
    "    \n",
    "    if mode == \"train\":        \n",
    "        img_filenames = train_images_filenames\n",
    "        lbl_filenames = train_labels\n",
    "        \n",
    "    else:\n",
    "        img_filenames = test_images_filenames\n",
    "        lbl_filenames = test_labels\n",
    "        \n",
    "    Detector = cv2.SIFT_create(feat_num)\n",
    "\n",
    "    for filename,labels in zip(img_filenames, lbl_filenames):\n",
    "        ima=cv2.imread(filename)\n",
    "        gray=cv2.cvtColor(ima, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if not dense:\n",
    "            kpt, des=Detector.detectAndCompute(gray,None)\n",
    "            \n",
    "        else:\n",
    "            kpt = create_dense_kp(gray.shape, step_size=step_size)                              \n",
    "            _, des = Detector.compute(gray, kpt)\n",
    "            \n",
    "        descriptors.append(des)\n",
    "        label_per_descriptor.append(labels)\n",
    "    \n",
    "    return descriptors, label_per_descriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This function is used to find visual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_visual_words(descriptors, k=128):\n",
    "    \n",
    "    D = np.vstack(descriptors)\n",
    "    codebook = MiniBatchKMeans(n_clusters=k, verbose=False, batch_size=k*20, compute_labels=False,\n",
    "                               reassignment_ratio=10**-4, random_state=42)\n",
    "    codebook.fit(D)\n",
    "    \n",
    "    visual_words=np.zeros((len(descriptors), k),dtype=np.float32)\n",
    "    \n",
    "    for i in range(len(descriptors)):\n",
    "        words=codebook.predict(descriptors[i])\n",
    "        visual_words[i,:]=np.bincount(words,minlength=k)\n",
    "        \n",
    "    return codebook, visual_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We get the most common words for each class and plot them to see if there are any significant differences between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Train_descriptors, train_labels = get_descriptors(dense=False, feat_num=500)\n",
    "codebook, visual_words = get_visual_words(Train_descriptors, 128)\n",
    "\n",
    "class_dict = {}\n",
    "\n",
    "for lbl, elem in zip(train_labels, visual_words):\n",
    "    if lbl not in class_dict.keys():\n",
    "        class_dict[lbl] = np.argsort(elem)[::-1][:10]\n",
    "    else:\n",
    "        class_dict[lbl] = np.concatenate((class_dict[lbl], np.argsort(elem)[::-1][:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = plt.rcParams[\"axes.prop_cycle\"]()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=4, ncols=2, figsize=(15, 20))\n",
    "\n",
    "for num, key in enumerate(class_dict.keys()):\n",
    "    c = next(colors)[\"color\"]\n",
    "    i = int(num/2)\n",
    "    j = int(num%2)\n",
    "    tmp_cls = pd.Series(class_dict[key]).value_counts()[:10]\n",
    "    ax[i][j].bar(tmp_cls.index, tmp_cls.values, color=c)\n",
    "    ax[i][j].title.set_text(\"Most common 10 words for \" + key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter search for SIFT and KNN with cross validation\n",
    "\n",
    "We tried different amount of local features, codebook sizes, distance metrics and n_neighbors.\n",
    "Since this takes a lot of time we ran it once and put the results in a csv file. \n",
    "We did a grid search with splitting the data into 8 for cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the results from the csv instead of running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_res_df = pd.read_csv(\"knn_hp_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_res_df = pd.DataFrame(columns=[\"n_features\", \"codebook_size\", \"n_neighbors\",\"dist_metric\",\n",
    "                                   \"mean_train_acc\", \"mean_test_acc\", \"mean_train_f1\", \"mean_test_f1\"])\n",
    "\n",
    "params = {\n",
    "    \"n_features\": np.arange(200, 800, 100),\n",
    "    #\"dense\": [True, False],\n",
    "    #\"step_size\": np.arange(10, 60, 10),\n",
    "    \"codebook_size\": np.arange(32, 256, 32),\n",
    "    \"n_neighbors\": np.arange(3, 9, 1),\n",
    "    \"metric\": [\"euclidean\", \"manhattan\", \"chebyshev\", \"minkowski\"]\n",
    "}\n",
    "\n",
    "for n in params[\"n_features\"]:\n",
    "    Train_descriptors, train_labels = get_descriptors(dense=False, feat_num=n)\n",
    "    for cs in params[\"codebook_size\"]:\n",
    "        codebook, visual_words = get_visual_words(Train_descriptors, cs)\n",
    "\n",
    "        print(n, cs)\n",
    "\n",
    "        knn = KNeighborsClassifier(n_jobs=-1)\n",
    "        knn_grid = GridSearchCV(knn, {k:params[k] for k in (\"n_neighbors\", \"metric\") if k in params}, cv=8,\n",
    "                                scoring=[\"accuracy\", \"f1_macro\"], refit=\"accuracy\", return_train_score=True)\n",
    "        knn_grid.fit(visual_words, train_labels) \n",
    "\n",
    "        print(\"Finished this iteration!\")\n",
    "        best_acc = np.argmin(knn_grid.cv_results_[\"rank_test_accuracy\"])\n",
    "        knn_res_df = knn_res_df.append({\n",
    "            \"n_features\": n,\n",
    "            \"codebook_size\": cs,\n",
    "            \"n_neighbors\": knn_grid.best_params_[\"n_neighbors\"],\n",
    "            \"dist_metric\": knn_grid.best_params_[\"metric\"],\n",
    "            \"mean_train_acc\": knn_grid.cv_results_[\"mean_train_accuracy\"][best_acc], \n",
    "            \"mean_test_acc\": knn_grid.cv_results_[\"mean_test_accuracy\"][best_acc], \n",
    "            \"mean_train_f1\": knn_grid.cv_results_[\"mean_train_f1_macro\"][best_acc], \n",
    "            \"mean_test_f1\": knn_grid.cv_results_[\"mean_test_f1_macro\"][best_acc]\n",
    "        }, ignore_index=True)\n",
    "        \n",
    "knn_res_df.to_csv(\"knn_hp_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of N_features, Codebook size and N_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_res_df.groupby(\"n_features\").mean()[\"mean_test_acc\"].plot(marker='o', linestyle=\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_res_df.groupby(\"codebook_size\").mean()[\"mean_test_acc\"].plot(marker='o', linestyle=\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_res_df.groupby(\"n_neighbors\").mean()[\"mean_test_acc\"].plot(marker='o', linestyle=\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For SIFT, best combination is:\n",
    "\n",
    "<b> N_features </b> = 500  <br>\n",
    "<b> Codebook_size </b> = 96 <br>\n",
    "<b> N_neighbors </b> = 8 <br>\n",
    "<b> Distance_metric </b> = euclidean\n",
    "\n",
    "<b> We can achieve a test accuracy of %58. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn_res_df.sort_values(\"mean_test_acc\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter search for Dense-SIFT and KNN\n",
    "\n",
    "We see that best n_feature size is 500 for SIFT, so we tried to tune the step size while keeping the n_features at 500.\n",
    "We did a grid search with splitting the data into 8 for cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the results from the csv instead of running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_dSIFT_res_df = pd.read_csv(\"knn_dSIFT_res.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_dSIFT_res_df = pd.DataFrame(columns=[\"step_size\", \"codebook_size\", \"n_neighbors\",\"dist_metric\",\n",
    "                                   \"mean_train_acc\", \"mean_test_acc\", \"mean_train_f1\", \"mean_test_f1\"])\n",
    "\n",
    "params = {\n",
    "    #\"dense\": [True, False],\n",
    "    \"step_size\": np.arange(10, 60, 10),\n",
    "    \"codebook_size\": np.arange(64, 256, 32),\n",
    "    \"n_neighbors\": np.arange(6, 9, 1),\n",
    "    \"metric\": [\"euclidean\", \"manhattan\", \"chebyshev\", \"minkowski\"]\n",
    "}\n",
    "\n",
    "for ss in params[\"step_size\"]:\n",
    "    Train_descriptors, train_labels = get_descriptors(feat_num=500, step_size=int(ss))\n",
    "    #Test_descriptors, test_labels = get_descriptors(False, n, ss, mode=\"test\")\n",
    "\n",
    "    for cs in params[\"codebook_size\"]:\n",
    "        codebook, visual_words = get_visual_words(Train_descriptors, cs)\n",
    "\n",
    "        ##visual_words_test=np.zeros((len(test_labels),cs), dtype=np.float32)\n",
    "        ##for i in range(len(Test_descriptors)):\n",
    "        ##    words = codebook.predict(Test_descriptors[i])\n",
    "        ##    visual_words_test[i,:] = np.bincount(words, minlength=cs)\n",
    "\n",
    "        print(ss, cs)\n",
    "\n",
    "        knn = KNeighborsClassifier(n_jobs=-1)\n",
    "        knn_grid = GridSearchCV(knn, {k:params[k] for k in (\"n_neighbors\", \"metric\") if k in params}, cv=8,\n",
    "                                scoring=[\"accuracy\", \"f1_macro\"], refit=\"accuracy\", return_train_score=True)\n",
    "        knn_grid.fit(visual_words, train_labels) \n",
    "\n",
    "        #test_preds = knn_grid.predict(visual_words_test)\n",
    "        #print(f1_score(test_labels, test_preds, average=\"micro\"))\n",
    "        print(\"Finished this iteration!\")\n",
    "        best_acc = np.argmin(knn_grid.cv_results_[\"rank_test_accuracy\"])\n",
    "        knn_dSIFT_res_df = knn_dSIFT_res_df.append({\n",
    "            \"step_size\": ss,\n",
    "            \"codebook_size\": cs,\n",
    "            \"n_neighbors\": knn_grid.best_params_[\"n_neighbors\"],\n",
    "            \"dist_metric\": knn_grid.best_params_[\"metric\"],\n",
    "            \"mean_train_acc\": knn_grid.cv_results_[\"mean_train_accuracy\"][best_acc], \n",
    "            \"mean_test_acc\": knn_grid.cv_results_[\"mean_test_accuracy\"][best_acc], \n",
    "            \"mean_train_f1\": knn_grid.cv_results_[\"mean_train_f1_macro\"][best_acc], \n",
    "            \"mean_test_f1\": knn_grid.cv_results_[\"mean_test_f1_macro\"][best_acc]\n",
    "        }, ignore_index=True)\n",
    "        \n",
    "knn_dSIFT_res_df.to_csv(\"knn_dSIFT_res.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of step size. We can see that a smaller step size is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn_dSIFT_res_df.groupby(\"step_size\").mean()[\"mean_test_acc\"].plot(marker='o', linestyle=\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Dense-SIFT, best combination is:\n",
    "\n",
    "<b> Step_size </b> = 10  <br>\n",
    "<b> Codebook_size </b> = 224 <br>\n",
    "<b> N_neighbors </b> = 8 <br>\n",
    "<b> Distance_metric </b> = manhattan\n",
    "\n",
    " We can achieve a test accuracy of <b> %79.</b>\n",
    "\n",
    "## Dense-SIFT clearly outperforms vanilla SIFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn_dSIFT_res_df.sort_values(\"mean_test_acc\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We tried without tuning Logistic Regression with the parameters of Dense-SIFT. \n",
    "\n",
    "It achieves <b> %99 </b> accuracy in train set but only <b> %78 </b> in test set, so it suffers from overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_descriptors, train_labels = get_descriptors(feat_num=500, step_size=10)\n",
    "Test_descriptors, test_labels = get_descriptors(feat_num=500, step_size=10, mode=\"test\")\n",
    "codebook, visual_words = get_visual_words(Train_descriptors, 224)\n",
    "\n",
    "visual_words_test=np.zeros((len(test_labels),224), dtype=np.float32)\n",
    "for i in range(len(Test_descriptors)):\n",
    "    words = codebook.predict(Test_descriptors[i])\n",
    "    visual_words_test[i,:] = np.bincount(words, minlength=224)\n",
    "\n",
    "lg = LogisticRegression(solver='liblinear')\n",
    "\n",
    "lg.fit(visual_words, train_labels)\n",
    "train_preds = lg.predict(visual_words)\n",
    "test_preds = lg.predict(visual_words_test)\n",
    "\n",
    "print(\"Train accuracy for LogReg: \", accuracy_score(train_labels, train_preds))\n",
    "print(\"Test accuracy for LogReg: \", accuracy_score(test_labels, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We did a simple hyperparameter tuning with only 2 parameters for Logistic Regression to see if we can overcome the overfitting problem.\n",
    "\n",
    "We did a grid search with splitting the data into 8 for cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_descriptors, train_labels = get_descriptors(feat_num=500, step_size=10)\n",
    "Test_descriptors, test_labels = get_descriptors(feat_num=500, step_size=10, mode=\"test\")\n",
    "codebook, visual_words = get_visual_words(Train_descriptors, 224)\n",
    "\n",
    "visual_words_test=np.zeros((len(test_labels),224), dtype=np.float32)\n",
    "for i in range(len(Test_descriptors)):\n",
    "    words = codebook.predict(Test_descriptors[i])\n",
    "    visual_words_test[i,:] = np.bincount(words, minlength=224)\n",
    "\n",
    "params = {\n",
    "    \"C\": np.arange(0.001, 1, 0.01),\n",
    "    \"max_iter\": np.arange(50, 550, 50)\n",
    "}\n",
    "    \n",
    "lg = LogisticRegression(solver='liblinear')\n",
    "\n",
    "lg_grid = GridSearchCV(lg, params, cv=8,\n",
    "                        scoring=[\"accuracy\", \"f1_macro\"], refit=\"accuracy\", return_train_score=True)\n",
    "lg_grid.fit(visual_words, train_labels) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best params for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we make predictions on the whole training and test sets to see the difference between performances in KNN and Logistic Regression\n",
    "\n",
    "We can see that Logistic Regression outperforms KNN but the gap between Train and Test performances are higher.\n",
    "\n",
    "<h5> Train Accuracy: KNN = % 84, Logistic Regression = %92 <br>\n",
    "Test Accuracy: KNN = % 79, Logistic Regression = %84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_descriptors, train_labels = get_descriptors(feat_num=500, step_size=10)\n",
    "Test_descriptors, test_labels = get_descriptors(feat_num=500, step_size=10, mode=\"test\")\n",
    "codebook, visual_words = get_visual_words(Train_descriptors, 224)\n",
    "\n",
    "visual_words_test=np.zeros((len(test_labels),224), dtype=np.float32)\n",
    "for i in range(len(Test_descriptors)):\n",
    "    words = codebook.predict(Test_descriptors[i])\n",
    "    visual_words_test[i,:] = np.bincount(words, minlength=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_jobs=-1, n_neighbors=8, metric=\"manhattan\")\n",
    "\n",
    "knn.fit(visual_words, train_labels)\n",
    "train_preds = knn.predict(visual_words)\n",
    "test_preds = knn.predict(visual_words_test)\n",
    "\n",
    "print(\"Train accuracy for KNN: \", round(accuracy_score(train_labels, train_preds), 3))\n",
    "print(\"Test accuracy for KNN: \", round(accuracy_score(test_labels, test_preds), 3))\n",
    "\n",
    "lg = LogisticRegression(C=0.001, max_iter=50, solver='liblinear')\n",
    "\n",
    "lg.fit(visual_words, train_labels)\n",
    "\n",
    "train_preds = lg.predict(visual_words)\n",
    "test_preds = lg.predict(visual_words_test)\n",
    "\n",
    "print(\"Train accuracy for LogReg: \", round(accuracy_score(train_labels, train_preds), 3))\n",
    "print(\"Test accuracy for LogReg: \", round(accuracy_score(test_labels, test_preds),3 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we try PCA with both KNN and Logistic Regression\n",
    "\n",
    "<h4> Changes in accuracy for training set: </h4>\n",
    "\n",
    "<b> KNN: </b> %84 to %82 <br>\n",
    "<b> Logistic Regression: </b> %92 to %81\n",
    "\n",
    "<h4> Changes in accuracy for test set: </h4>\n",
    "\n",
    "<b> KNN: </b> %79 to %75 <br>\n",
    "<b> Logistic Regression: </b> %84 to %75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> We can see that even though Logistic Regression was better before, it's performance drops gradually after PCA and becomes nearly identical with KNN. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=64)\n",
    "VWpca = pca.fit_transform(visual_words)\n",
    "\n",
    "knnpca = KNeighborsClassifier(n_jobs=-1, n_neighbors=8, metric=\"manhattan\")\n",
    "lgpca = LogisticRegression(C=0.001, max_iter=50, solver='liblinear')\n",
    "\n",
    "knnpca.fit(VWpca, train_labels) \n",
    "lgpca.fit(VWpca, train_labels) \n",
    "vwtestpca = pca.transform(visual_words_test)\n",
    "\n",
    "accuracy = round(knnpca.score(VWpca, train_labels), 3)\n",
    "print(\"Train Accuracy with PCA for KNN:\", accuracy)\n",
    "accuracy = round(knnpca.score(vwtestpca, test_labels), 3)\n",
    "print(\"Test Accuracy with PCA for KNN:\", accuracy)\n",
    "\n",
    "accuracy = round(lgpca.score(VWpca, train_labels), 3)\n",
    "print(\"Train Accuracy with PCA for LogReg:\", accuracy)\n",
    "accuracy = round(lgpca.score(vwtestpca, test_labels), 3)\n",
    "print(\"Test Accuracy with PCA for LogReg:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA for both KNN and Logistic Regression\n",
    "\n",
    "<h4> Changes in accuracy for training set: </h4>\n",
    "\n",
    "<b> KNN: </b> %84 to %92 <br>\n",
    "<b> Logistic Regression: </b> %92 to %88\n",
    "\n",
    "<h4> Changes in accuracy for test set: </h4>\n",
    "\n",
    "<b> KNN: </b> %79 to %84 <br>\n",
    "<b> Logistic Regression: </b> %84 to %72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> While the performance of Logistic Regression drops, KNN's improve and get even better than before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=7)\n",
    "VWlda = lda.fit_transform(visual_words,train_labels)\n",
    "\n",
    "knnlda = KNeighborsClassifier(n_jobs=-1, n_neighbors=8, metric=\"manhattan\")\n",
    "lglda = LogisticRegression(C=0.001, max_iter=50, solver='liblinear')\n",
    "\n",
    "knnlda.fit(VWlda, train_labels) \n",
    "lglda.fit(VWlda, train_labels) \n",
    "\n",
    "vwtestlda = lda.transform(visual_words_test)\n",
    "\n",
    "accuracy = round(knnlda.score(VWlda, train_labels), 3)\n",
    "print(\"Train Accuracy with PCA for KNN:\", accuracy)\n",
    "accuracy = round(lglda.score(VWlda, train_labels), 3)\n",
    "print(\"Train Accuracy with PCA for LogReg:\", accuracy)\n",
    "\n",
    "accuracy = round(knnlda.score(vwtestlda, test_labels), 3)\n",
    "print(\"Test Accuracy with PCA for KNN:\", accuracy)\n",
    "accuracy = round(lglda.score(vwtestlda, test_labels), 3)\n",
    "print(\"Test Accuracy with PCA for LogReg:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "<h3> Best performing combinations are: </h3>\n",
    "\n",
    "<b> Descriptor Method: </b> Dense_SIFT <br>\n",
    "<b> Step_size </b> = 10  <br>\n",
    "<b> Codebook_size </b> = 224 <br>\n",
    "\n",
    "<h3> For Predictors: </h3> <br>\n",
    "\n",
    "Either <b> KNN </b> with given parameters <br>\n",
    "<b> N_neighbors </b> = 8 <br>\n",
    "<b> Distance_metric </b> = manhattan <br>\n",
    "after applying <b> LDA. </b>\n",
    "\n",
    "Or <b> Logistic Regression </b> with given parameters <br>\n",
    "<b> C </b> = 0.001 <br>\n",
    "<b> Max_iter </b> = 50 <br>\n",
    "without <b> LDA </b> or <b> PCA </b>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Best performance achieved with both descriptors: </h3>\n",
    "\n",
    "<b>%92</b> Accuracy in Train Set <br>\n",
    "<b>%84</b> Accuracy in Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the performances of each class.\n",
    "\n",
    "We see that the worst performance is in the <b> Opencountry </b> and <b> coast </b> classes for both of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = knnlda.predict(vwtestlda)\n",
    "print(classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = lg.predict(visual_words_test)\n",
    "print(classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oc_imgs = [img for img in test_images_filenames if \"Opencountry\" in img]\n",
    "random.shuffle(oc_imgs)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15,15))\n",
    "fig.suptitle(\"Some images from Opencountry class\")\n",
    "\n",
    "for num, img in enumerate(oc_imgs[:4]):\n",
    "    i = int(num/2)\n",
    "    j = int(num%2)\n",
    "    axes[i][j].imshow(cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    \n",
    "cst_imgs = [img for img in test_images_filenames if \"coast\" in img]\n",
    "random.shuffle(cst_imgs)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15,15))\n",
    "fig.suptitle(\"Some images from coast class\")\n",
    "\n",
    "for num, img in enumerate(cst_imgs[:4]):\n",
    "    i = int(num/2)\n",
    "    j = int(num%2)\n",
    "    axes[i][j].imshow(cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Dense SIFT with tiny steps</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"step_size\": np.arange(5, 50, 5),\n",
    "    \"codebook_size\": np.arange(64, 256, 32),\n",
    "    \"n_neighbors\": np.arange(3, 9, 1),\n",
    "    \"metric\": [\"euclidean\", \"manhattan\", \"chebyshev\", \"minkowski\"]\n",
    "}\n",
    "\n",
    "image_size = [(64, 64), (128, 128), (256, 256)]\n",
    "# resize evey image in train_image_dataset and test_image_dataset\n",
    "for dim in image_size:\n",
    "    train_images_filenames = cv2.resize(img for img in train_images_filenames, dim)\n",
    "    test_images_filenames = cv2.resize(img for img in test_images_filenames, dim)\n",
    "    \n",
    "    for ss in params[\"step_size\"]:\n",
    "        Train_descriptors, train_labels = get_descriptors(feat_num=500, step_size=int(ss))\n",
    "        for cs in params[\"codebook_size\"]:\n",
    "            codebook, visual_words = get_visual_words(Train_descriptors, cs)\n",
    "\n",
    "            knn = KNeighborsClassifier(n_jobs=-1)\n",
    "            knn_grid = GridSearchCV(knn, {k:params[k] for k in (\"n_neighbors\", \"metric\") if k in params}, cv=8,\n",
    "                                    scoring=[\"accuracy\", \"f1_macro\"], refit=\"accuracy\", return_train_score=True)\n",
    "            knn_grid.fit(visual_words, train_labels)\n",
    "            \n",
    "            knn_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>L2 Norm</b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_visual_words_norm(descriptors, k=128, L2norm = True, power_norm_method = 'yeo-johnson'):\n",
    "    \n",
    "    D = np.vstack(descriptors)\n",
    "    \n",
    "    # normalization of descriptors with L2-norm\n",
    "    if L2norm is True:\n",
    "        descriptors = LA.norm(descriptors.ravel(), ord=2)\n",
    "    else\n",
    "        descriptors = power_transform(descriptors, method=power_norm_method)\n",
    "    # normalization of descriptors with power-norm\n",
    "    # descriptors = power_transform(descriptors, method='box-cox')\n",
    "    # descriptors = power_transform(descriptors, method='yeo-johnson')\n",
    "    \n",
    "    codebook = MiniBatchKMeans(n_clusters=k, verbose=False, batch_size=k*20, compute_labels=False,\n",
    "                               reassignment_ratio=10**-4, random_state=42)\n",
    "    codebook.fit(D)\n",
    "    \n",
    "    visual_words=np.zeros((len(descriptors), k),dtype=np.float32)\n",
    "    \n",
    "    for i in range(len(descriptors)):\n",
    "        words=codebook.predict(descriptors[i])\n",
    "        visual_words[i,:]=np.bincount(words,minlength=k)\n",
    "        \n",
    "    return codebook, visual_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>SVM Classifier</b>\n",
    "get the descriptors and then do create SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4510ae2205fc661e79c1256e94d74e13c5222290d1a25941673cb48af3ea7c0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
