{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "W3_BowTask.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1wWsSmz98UW8tbu8oClh3c1YT9dBXjYZG",
      "authorship_tag": "ABX9TyMg05EVEZi24Nh38KF+Qh86",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myazann/M3-Machine-Learning/blob/main/W3_BowTask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SDOCkJ-oeU5v"
      },
      "outputs": [],
      "source": [
        "!cp drive/MyDrive/utils.py .\n",
        "!cp drive/MyDrive/mlp_MIT_8_scene.py .\n",
        "!cp drive/MyDrive/patch_based_mlp_MIT_8_scene.py .\n",
        "\n",
        "!cp -a drive/MyDrive/MIT_split .\n",
        "!mkdir work"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from utils import *\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Reshape\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import os"
      ],
      "metadata": {
        "id": "ff1wj6gZfXvy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf MIT_split_patches"
      ],
      "metadata": {
        "id": "R7zDFkQL-k6a"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#user defined variables\n",
        "PATCH_SIZE  = 8\n",
        "BATCH_SIZE  = 32\n",
        "DATASET_DIR = 'MIT_split'\n",
        "PATCHES_DIR = 'MIT_split_patches'\n",
        "MODEL_FNAME = 'work/patch_based_mlp.h5'\n",
        "\n",
        "def build_mlp(input_size=PATCH_SIZE,phase='TRAIN'):\n",
        "  model = Sequential()\n",
        "  model.add(Reshape((input_size*input_size*3,),input_shape=(input_size, input_size, 3)))\n",
        "  model.add(Dense(units=2048, activation='relu',name='second'))\n",
        "  #model.add(BatchNormalization())\n",
        "  #model.add(Dropout(0.2))\n",
        "  model.add(Dense(units=1024, activation='relu', name='third'))\n",
        "  #model.add(Dropout(0.2))\n",
        "  model.add(Dense(units=512, activation='relu', name='fourth'))\n",
        "  if phase=='TEST':\n",
        "    model.add(Dense(units=8, activation='linear')) # In test phase we softmax the average output over the image patches\n",
        "  else:\n",
        "    model.add(Dense(units=8, activation='softmax'))\n",
        "  return model\n",
        "\n",
        "if not os.path.exists(DATASET_DIR):\n",
        "  colorprint(Color.RED, 'ERROR: dataset directory '+DATASET_DIR+' do not exists!\\n')\n",
        "  quit()\n",
        "if not os.path.exists(PATCHES_DIR):\n",
        "  colorprint(Color.YELLOW, 'WARNING: patches dataset directory '+PATCHES_DIR+' do not exists!\\n')\n",
        "  colorprint(Color.BLUE, 'Creating image patches dataset into '+PATCHES_DIR+'\\n')\n",
        "  generate_image_patches_db(DATASET_DIR,PATCHES_DIR,patch_size=PATCH_SIZE)\n",
        "  colorprint(Color.BLUE, 'Done!\\n')"
      ],
      "metadata": {
        "id": "V3PGv_WkfEpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colorprint(Color.BLUE, 'Building MLP model...\\n')\n",
        "model = build_mlp(input_size=PATCH_SIZE)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "colorprint(Color.BLUE, 'Done!\\n')\n",
        "\n",
        "if not os.path.exists(MODEL_FNAME):\n",
        "  colorprint(Color.YELLOW, 'WARNING: model file '+MODEL_FNAME+' do not exists!\\n')\n",
        "  colorprint(Color.BLUE, 'Start training...\\n')\n",
        "  # this is the dataset configuration we will use for training\n",
        "  # only rescaling\n",
        "  train_datagen = ImageDataGenerator(\n",
        "          rescale=1./255,\n",
        "          horizontal_flip=True)\n",
        "  \n",
        "  # this is the dataset configuration we will use for testing:\n",
        "  # only rescaling\n",
        "  test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "  \n",
        "  # this is a generator that will read pictures found in\n",
        "  # subfolers of 'data/train', and indefinitely generate\n",
        "  # batches of augmented image data\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "          PATCHES_DIR+'/train',  # this is the target directory\n",
        "          target_size=(PATCH_SIZE, PATCH_SIZE),  # all images will be resized to PATCH_SIZExPATCH_SIZE\n",
        "          batch_size=BATCH_SIZE,\n",
        "          classes = ['coast','forest','highway','inside_city','mountain','Opencountry','street','tallbuilding'],\n",
        "          class_mode='categorical')  # since we use binary_crossentropy loss, we need categorical labels\n",
        "  \n",
        "  # this is a similar generator, for validation data\n",
        "  validation_generator = test_datagen.flow_from_directory(\n",
        "          PATCHES_DIR+'/test',\n",
        "          target_size=(PATCH_SIZE, PATCH_SIZE),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          classes = ['coast','forest','highway','inside_city','mountain','Opencountry','street','tallbuilding'],\n",
        "          class_mode='categorical')\n",
        "  \n",
        "  model.fit_generator(\n",
        "          train_generator,\n",
        "          steps_per_epoch=18810 // BATCH_SIZE,\n",
        "          epochs=75,\n",
        "          validation_data=validation_generator,\n",
        "          validation_steps=8070 // BATCH_SIZE)\n",
        "  \n",
        "  colorprint(Color.BLUE, 'Done!\\n')\n",
        "  colorprint(Color.BLUE, 'Saving the model into '+MODEL_FNAME+' \\n')\n",
        "  model.save_weights(MODEL_FNAME)  # always save your weights after training or during training\n",
        "  colorprint(Color.BLUE, 'Done!\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evJrEMDdu18J",
        "outputId": "e80df09d-4f5d-4bd0-a925-17e1f47e2a49"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34mBuilding MLP model...\n",
            "\u001b[0mModel: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_10 (Reshape)        (None, 192)               0         \n",
            "                                                                 \n",
            " second (Dense)              (None, 2048)              395264    \n",
            "                                                                 \n",
            " third (Dense)               (None, 1024)              2098176   \n",
            "                                                                 \n",
            " fourth (Dense)              (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 8)                 4104      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,022,344\n",
            "Trainable params: 3,022,344\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\u001b[34mDone!\n",
            "\u001b[0m\u001b[33mWARNING: model file work/patch_based_mlp.h5 do not exists!\n",
            "\u001b[0m\u001b[34mStart training...\n",
            "\u001b[0mFound 1926144 images belonging to 8 classes.\n",
            "Found 826368 images belonging to 8 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n",
            "587/587 [==============================] - 23s 38ms/step - loss: 1.9947 - accuracy: 0.2071 - val_loss: 1.9211 - val_accuracy: 0.2510\n",
            "Epoch 2/75\n",
            "587/587 [==============================] - 22s 37ms/step - loss: 1.8808 - accuracy: 0.2744 - val_loss: 1.8216 - val_accuracy: 0.2834\n",
            "Epoch 3/75\n",
            "587/587 [==============================] - 22s 37ms/step - loss: 1.7932 - accuracy: 0.3085 - val_loss: 1.7499 - val_accuracy: 0.3113\n",
            "Epoch 4/75\n",
            "587/587 [==============================] - 22s 37ms/step - loss: 1.7388 - accuracy: 0.3375 - val_loss: 1.6940 - val_accuracy: 0.3720\n",
            "Epoch 5/75\n",
            "587/587 [==============================] - 22s 37ms/step - loss: 1.7017 - accuracy: 0.3476 - val_loss: 1.6489 - val_accuracy: 0.3695\n",
            "Epoch 6/75\n",
            "587/587 [==============================] - 22s 37ms/step - loss: 1.6723 - accuracy: 0.3649 - val_loss: 1.6419 - val_accuracy: 0.3735\n",
            "Epoch 7/75\n",
            "587/587 [==============================] - 22s 37ms/step - loss: 1.6514 - accuracy: 0.3774 - val_loss: 1.5968 - val_accuracy: 0.4002\n",
            "Epoch 8/75\n",
            "587/587 [==============================] - 22s 37ms/step - loss: 1.6392 - accuracy: 0.3838 - val_loss: 1.5900 - val_accuracy: 0.4117\n",
            "Epoch 9/75\n",
            "587/587 [==============================] - 22s 37ms/step - loss: 1.6207 - accuracy: 0.3930 - val_loss: 1.5738 - val_accuracy: 0.4002\n",
            "Epoch 10/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.6043 - accuracy: 0.4031 - val_loss: 1.5733 - val_accuracy: 0.4094\n",
            "Epoch 11/75\n",
            "587/587 [==============================] - 22s 37ms/step - loss: 1.5847 - accuracy: 0.4115 - val_loss: 1.5532 - val_accuracy: 0.4219\n",
            "Epoch 12/75\n",
            "587/587 [==============================] - 22s 37ms/step - loss: 1.5737 - accuracy: 0.4177 - val_loss: 1.5414 - val_accuracy: 0.4328\n",
            "Epoch 13/75\n",
            "587/587 [==============================] - 22s 37ms/step - loss: 1.5600 - accuracy: 0.4234 - val_loss: 1.5343 - val_accuracy: 0.4267\n",
            "Epoch 14/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.5565 - accuracy: 0.4232 - val_loss: 1.5217 - val_accuracy: 0.4369\n",
            "Epoch 15/75\n",
            "587/587 [==============================] - 21s 37ms/step - loss: 1.5512 - accuracy: 0.4262 - val_loss: 1.5108 - val_accuracy: 0.4375\n",
            "Epoch 16/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.5282 - accuracy: 0.4364 - val_loss: 1.5215 - val_accuracy: 0.4412\n",
            "Epoch 17/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.5244 - accuracy: 0.4313 - val_loss: 1.5117 - val_accuracy: 0.4535\n",
            "Epoch 18/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.5030 - accuracy: 0.4459 - val_loss: 1.4911 - val_accuracy: 0.4492\n",
            "Epoch 19/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.5093 - accuracy: 0.4477 - val_loss: 1.4991 - val_accuracy: 0.4578\n",
            "Epoch 20/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.4958 - accuracy: 0.4485 - val_loss: 1.4819 - val_accuracy: 0.4603\n",
            "Epoch 21/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.4925 - accuracy: 0.4533 - val_loss: 1.4707 - val_accuracy: 0.4618\n",
            "Epoch 22/75\n",
            "587/587 [==============================] - 25s 43ms/step - loss: 1.4965 - accuracy: 0.4563 - val_loss: 1.4700 - val_accuracy: 0.4695\n",
            "Epoch 23/75\n",
            "587/587 [==============================] - 22s 37ms/step - loss: 1.4824 - accuracy: 0.4536 - val_loss: 1.4880 - val_accuracy: 0.4577\n",
            "Epoch 24/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.4763 - accuracy: 0.4616 - val_loss: 1.4663 - val_accuracy: 0.4670\n",
            "Epoch 25/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.4892 - accuracy: 0.4575 - val_loss: 1.4338 - val_accuracy: 0.4736\n",
            "Epoch 26/75\n",
            "587/587 [==============================] - 22s 37ms/step - loss: 1.4652 - accuracy: 0.4613 - val_loss: 1.4807 - val_accuracy: 0.4566\n",
            "Epoch 27/75\n",
            "587/587 [==============================] - 22s 37ms/step - loss: 1.4567 - accuracy: 0.4689 - val_loss: 1.4503 - val_accuracy: 0.4785\n",
            "Epoch 28/75\n",
            "587/587 [==============================] - 22s 37ms/step - loss: 1.4647 - accuracy: 0.4718 - val_loss: 1.4288 - val_accuracy: 0.4843\n",
            "Epoch 29/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.4647 - accuracy: 0.4637 - val_loss: 1.4268 - val_accuracy: 0.4867\n",
            "Epoch 30/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.4404 - accuracy: 0.4729 - val_loss: 1.4414 - val_accuracy: 0.4752\n",
            "Epoch 31/75\n",
            "587/587 [==============================] - 26s 43ms/step - loss: 1.4270 - accuracy: 0.4716 - val_loss: 1.4216 - val_accuracy: 0.4852\n",
            "Epoch 32/75\n",
            "587/587 [==============================] - 26s 44ms/step - loss: 1.4371 - accuracy: 0.4749 - val_loss: 1.4520 - val_accuracy: 0.4798\n",
            "Epoch 33/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.4156 - accuracy: 0.4823 - val_loss: 1.3988 - val_accuracy: 0.4939\n",
            "Epoch 34/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.4156 - accuracy: 0.4879 - val_loss: 1.4008 - val_accuracy: 0.4953\n",
            "Epoch 35/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.4259 - accuracy: 0.4820 - val_loss: 1.4023 - val_accuracy: 0.4949\n",
            "Epoch 36/75\n",
            "587/587 [==============================] - 22s 37ms/step - loss: 1.4151 - accuracy: 0.4859 - val_loss: 1.4202 - val_accuracy: 0.4876\n",
            "Epoch 37/75\n",
            "587/587 [==============================] - 22s 37ms/step - loss: 1.4113 - accuracy: 0.4841 - val_loss: 1.3897 - val_accuracy: 0.4945\n",
            "Epoch 38/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.4094 - accuracy: 0.4845 - val_loss: 1.3782 - val_accuracy: 0.4965\n",
            "Epoch 39/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.3911 - accuracy: 0.4903 - val_loss: 1.4224 - val_accuracy: 0.4800\n",
            "Epoch 40/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.3926 - accuracy: 0.4971 - val_loss: 1.3898 - val_accuracy: 0.5006\n",
            "Epoch 41/75\n",
            "587/587 [==============================] - 22s 37ms/step - loss: 1.3975 - accuracy: 0.4930 - val_loss: 1.3735 - val_accuracy: 0.5050\n",
            "Epoch 42/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.3866 - accuracy: 0.4959 - val_loss: 1.3981 - val_accuracy: 0.5007\n",
            "Epoch 43/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.3944 - accuracy: 0.4942 - val_loss: 1.3749 - val_accuracy: 0.5073\n",
            "Epoch 44/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.3756 - accuracy: 0.5034 - val_loss: 1.3755 - val_accuracy: 0.5135\n",
            "Epoch 45/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.3690 - accuracy: 0.5038 - val_loss: 1.3750 - val_accuracy: 0.5026\n",
            "Epoch 46/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.3915 - accuracy: 0.4932 - val_loss: 1.3381 - val_accuracy: 0.5161\n",
            "Epoch 47/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.3680 - accuracy: 0.5045 - val_loss: 1.3813 - val_accuracy: 0.4974\n",
            "Epoch 48/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.3655 - accuracy: 0.5039 - val_loss: 1.3655 - val_accuracy: 0.5058\n",
            "Epoch 49/75\n",
            "587/587 [==============================] - 22s 37ms/step - loss: 1.3677 - accuracy: 0.5034 - val_loss: 1.3638 - val_accuracy: 0.5051\n",
            "Epoch 50/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.3590 - accuracy: 0.5040 - val_loss: 1.3520 - val_accuracy: 0.5247\n",
            "Epoch 51/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.3537 - accuracy: 0.5110 - val_loss: 1.3465 - val_accuracy: 0.5161\n",
            "Epoch 52/75\n",
            "587/587 [==============================] - 26s 44ms/step - loss: 1.3500 - accuracy: 0.5132 - val_loss: 1.3476 - val_accuracy: 0.5091\n",
            "Epoch 53/75\n",
            "587/587 [==============================] - 26s 44ms/step - loss: 1.3482 - accuracy: 0.5117 - val_loss: 1.3536 - val_accuracy: 0.5033\n",
            "Epoch 54/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.3432 - accuracy: 0.5123 - val_loss: 1.3614 - val_accuracy: 0.5171\n",
            "Epoch 55/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.3447 - accuracy: 0.5162 - val_loss: 1.3521 - val_accuracy: 0.5170\n",
            "Epoch 56/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.3192 - accuracy: 0.5231 - val_loss: 1.3374 - val_accuracy: 0.5277\n",
            "Epoch 57/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.3433 - accuracy: 0.5181 - val_loss: 1.3575 - val_accuracy: 0.5084\n",
            "Epoch 58/75\n",
            "587/587 [==============================] - 26s 44ms/step - loss: 1.3345 - accuracy: 0.5155 - val_loss: 1.3280 - val_accuracy: 0.5141\n",
            "Epoch 59/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.3328 - accuracy: 0.5191 - val_loss: 1.3466 - val_accuracy: 0.5176\n",
            "Epoch 60/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.3177 - accuracy: 0.5269 - val_loss: 1.3242 - val_accuracy: 0.5244\n",
            "Epoch 61/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.3168 - accuracy: 0.5236 - val_loss: 1.3449 - val_accuracy: 0.5091\n",
            "Epoch 62/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.3158 - accuracy: 0.5285 - val_loss: 1.3292 - val_accuracy: 0.5231\n",
            "Epoch 63/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.3317 - accuracy: 0.5168 - val_loss: 1.3138 - val_accuracy: 0.5303\n",
            "Epoch 64/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.3175 - accuracy: 0.5214 - val_loss: 1.3241 - val_accuracy: 0.5262\n",
            "Epoch 65/75\n",
            "587/587 [==============================] - 26s 43ms/step - loss: 1.3209 - accuracy: 0.5226 - val_loss: 1.3164 - val_accuracy: 0.5289\n",
            "Epoch 66/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.3028 - accuracy: 0.5294 - val_loss: 1.3275 - val_accuracy: 0.5252\n",
            "Epoch 67/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.2966 - accuracy: 0.5284 - val_loss: 1.3240 - val_accuracy: 0.5195\n",
            "Epoch 68/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.3197 - accuracy: 0.5216 - val_loss: 1.3148 - val_accuracy: 0.5331\n",
            "Epoch 69/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.3139 - accuracy: 0.5247 - val_loss: 1.3219 - val_accuracy: 0.5270\n",
            "Epoch 70/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.2949 - accuracy: 0.5314 - val_loss: 1.3263 - val_accuracy: 0.5226\n",
            "Epoch 71/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.3037 - accuracy: 0.5287 - val_loss: 1.2998 - val_accuracy: 0.5327\n",
            "Epoch 72/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.2883 - accuracy: 0.5367 - val_loss: 1.2802 - val_accuracy: 0.5475\n",
            "Epoch 73/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.2885 - accuracy: 0.5367 - val_loss: 1.3128 - val_accuracy: 0.5188\n",
            "Epoch 74/75\n",
            "587/587 [==============================] - 21s 36ms/step - loss: 1.2888 - accuracy: 0.5351 - val_loss: 1.3082 - val_accuracy: 0.5291\n",
            "Epoch 75/75\n",
            "587/587 [==============================] - 26s 44ms/step - loss: 1.2919 - accuracy: 0.5283 - val_loss: 1.3255 - val_accuracy: 0.5186\n",
            "\u001b[34mDone!\n",
            "\u001b[0m\u001b[34mSaving the model into work/patch_based_mlp.h5 \n",
            "\u001b[0m\u001b[34mDone!\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Patch size=64 -> Test_acc=%74 <br>\n",
        "Patch size=32 -> Test_acc=%73 <br>\n",
        "Patch size=16 -> Test_acc=%60 <br>\n",
        "Patch size=8 -> Test_acc=%56 <br>"
      ],
      "metadata": {
        "id": "8-JzYv7J9Pq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colorprint(Color.BLUE, 'Building MLP model for testing...\\n')\n",
        "\n",
        "model = build_mlp(input_size=PATCH_SIZE, phase='TEST')\n",
        "print(model.summary())\n",
        "\n",
        "colorprint(Color.BLUE, 'Done!\\n')\n",
        "\n",
        "colorprint(Color.BLUE, 'Loading weights from '+MODEL_FNAME+' ...\\n')\n",
        "print ('\\n')\n",
        "\n",
        "model.load_weights(MODEL_FNAME)\n",
        "\n",
        "colorprint(Color.BLUE, 'Done!\\n')\n",
        "\n",
        "colorprint(Color.BLUE, 'Start evaluation ...\\n')\n",
        "\n",
        "directory = DATASET_DIR+'/test'\n",
        "classes = {'coast':0,'forest':1,'highway':2,'inside_city':3,'mountain':4,'Opencountry':5,'street':6,'tallbuilding':7}\n",
        "correct = 0.\n",
        "total   = 807\n",
        "count   = 0\n",
        "\n",
        "for class_dir in os.listdir(directory):\n",
        "    cls = classes[class_dir]\n",
        "    for imname in os.listdir(os.path.join(directory,class_dir)):\n",
        "      im = Image.open(os.path.join(directory,class_dir,imname))\n",
        "      patches = image.extract_patches_2d(np.array(im), (PATCH_SIZE, PATCH_SIZE), max_patches=int(np.array(im).shape[0]/PATCH_SIZE)**2)\n",
        "      out = model.predict(patches/255.)\n",
        "      predicted_cls = np.argmax(softmax(np.mean(out,axis=0)) )\n",
        "      if predicted_cls == cls:\n",
        "        correct+=1\n",
        "      count += 1\n",
        "      print('Evaluated images: '+str(count)+' / '+str(total), end='\\r')\n",
        "    \n",
        "colorprint(Color.BLUE, 'Done!\\n')\n",
        "colorprint(Color.GREEN, 'Test Acc. = '+str(correct/total)+'\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbME0auPfgjQ",
        "outputId": "b8527bd9-896e-4a0c-89d8-339e2df636ad"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34mBuilding MLP model for testing...\n",
            "\u001b[0mModel: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_11 (Reshape)        (None, 192)               0         \n",
            "                                                                 \n",
            " second (Dense)              (None, 2048)              395264    \n",
            "                                                                 \n",
            " third (Dense)               (None, 1024)              2098176   \n",
            "                                                                 \n",
            " fourth (Dense)              (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 8)                 4104      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,022,344\n",
            "Trainable params: 3,022,344\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\u001b[34mDone!\n",
            "\u001b[0m\u001b[34mLoading weights from work/patch_based_mlp.h5 ...\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[34mDone!\n",
            "\u001b[0m\u001b[34mStart evaluation ...\n",
            "\u001b[34mDone!\n",
            "\u001b[0m\u001b[32mTest Acc. = 0.563816604708798\n",
            "\u001b[0m"
          ]
        }
      ]
    }
  ]
}